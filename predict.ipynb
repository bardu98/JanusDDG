{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80d0d193-11f5-4e42-b76f-99c49e887da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "#install required packages\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "# Helper function for visualization.\n",
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.data import Dataset\n",
    "import torch_geometric.utils as pyg_utils\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool,GATv2Conv\n",
    "from torch_geometric.nn.models import GCN, GAT\n",
    "from torch.nn import Linear\n",
    "\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch_geometric.utils import softmax\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import random\n",
    "from sklearn.metrics import root_mean_squared_error,mean_absolute_error\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4522ad10-397a-4b36-abe8-3c215b897876",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)  # Python random\n",
    "    np.random.seed(seed)  # Numpy random\n",
    "    torch.manual_seed(seed)  # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU (un singolo dispositivo)\n",
    "    torch.cuda.manual_seed_all(seed)  # PyTorch GPU (tutti i dispositivi, se usi multi-GPU)\n",
    "    torch.backends.cudnn.deterministic = True  # Comportamento deterministico di cuDNN\n",
    "    torch.backends.cudnn.benchmark = False  # Evita che cuDNN ottimizzi dinamicamente (influisce su riproducibilit√†)\n",
    "\n",
    "# Imposta il seed\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd53fc53-6a66-4f06-aa44-c6e5ac8c52f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "class DeltaDataset(Dataset):\n",
    "    def __init__(self, data, dim_embedding, inv = False):\n",
    "        self.data = data\n",
    "        self.dim_embedding = dim_embedding\n",
    "        self.inv = inv\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "\n",
    "        if self.inv: \n",
    "            return {\n",
    "                'id': sample['id'],\n",
    "                'wild_type': torch.tensor(sample['mut_type'], dtype=torch.float32),    #inverto mut con wild \n",
    "                'mut_type': torch.tensor(sample['wild_type'], dtype=torch.float32),    #inverto mut con wild             \n",
    "                'length': torch.tensor(sample['length'], dtype=torch.float32),\n",
    "                }\n",
    "\n",
    "        else:\n",
    "            return {\n",
    "                'id': sample['id'],\n",
    "                'wild_type': torch.tensor(sample['wild_type'], dtype=torch.float32),\n",
    "                'mut_type': torch.tensor(sample['mut_type'],dtype=torch.float32),\n",
    "                'length': torch.tensor(sample['length'], dtype=torch.float32),\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37194b0e-d9a3-4928-aa15-b510cbe7a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def collate_fn(batch):\n",
    "    max_len = max(sample['wild_type'].shape[0] for sample in batch)  \n",
    "    max_features = max(sample['wild_type'].shape[1] for sample in batch)  # Max feature size\n",
    "\n",
    "    padded_batch = {\n",
    "        'id': [],\n",
    "        'wild_type': [],\n",
    "        'mut_type': [],\n",
    "        'length': [],\n",
    "        }\n",
    "    for sample in batch:\n",
    "        wild_type_padded = F.pad(sample['wild_type'], (0, max_features - sample['wild_type'].shape[1], \n",
    "                                                       0, max_len - sample['wild_type'].shape[0]))\n",
    "        mut_type_padded = F.pad(sample['mut_type'], (0, max_features - sample['mut_type'].shape[1], \n",
    "                                                     0, max_len - sample['mut_type'].shape[0]))\n",
    "\n",
    "        padded_batch['id'].append(sample['id'])  \n",
    "        padded_batch['wild_type'].append(wild_type_padded)  \n",
    "        padded_batch['mut_type'].append(mut_type_padded)  \n",
    "        padded_batch['length'].append(sample['length'])#append(torch.tensor(sample['length'], dtype=torch.float32))  \n",
    "\n",
    "    # Convert list of tensors into a single batch tensor\n",
    "    padded_batch['wild_type'] = torch.stack(padded_batch['wild_type'])  # Shape: (batch_size, max_len, max_features)\n",
    "    padded_batch['mut_type'] = torch.stack(padded_batch['mut_type'])  \n",
    "    padded_batch['length'] = torch.stack(padded_batch['length'])  \n",
    "    \n",
    "    return padded_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "929f7e6d-973d-4fb4-bf11-e89af78108e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cross_Attention_DDG(nn.Module):\n",
    "    \n",
    "    def __init__(self, base_module, cross_att=False, dual_cross_att= False,**transf_parameters):\n",
    "        super().__init__()\n",
    "        self.base_ddg = base_module(**transf_parameters, cross_att=cross_att, dual_cross_att= dual_cross_att).to(device)\n",
    "    \n",
    "    def forward(self, x_wild, x_mut, length, train = True):\n",
    "\n",
    "        delta_x = x_wild - x_mut\n",
    "        output_TCA = self.base_ddg(delta_x, x_wild, length)\n",
    "\n",
    "        # inv Janus\n",
    "        delta_x_inv = x_mut -x_wild\n",
    "        output_TCA_inv = self.base_ddg(delta_x_inv, x_mut, length)\n",
    "        \n",
    "        return (output_TCA - output_TCA_inv)/2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a893ceaa-987b-4541-aa53-44b2a370ea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_model_from_batch(batch, model, device,train=True):\n",
    "\n",
    "    '''Dato un modello pytorch e batch restituisce: output_modello, True labels'''\n",
    "    \n",
    "    x_wild = batch['wild_type'].float().to(device)\n",
    "    x_mut = batch['mut_type'].float().to(device)\n",
    "    length = batch['length'].to(device)\n",
    "    output_ddg = model(x_wild, x_mut, length, train = train)\n",
    "    \n",
    "    return output_ddg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c98febd2-26c0-4c75-9768-9a9871b263e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def apply_masked_pooling(position_attn_output, padding_mask):\n",
    "\n",
    "    # Convert mask to float for element-wise multiplication\n",
    "    padding_mask = padding_mask.float()\n",
    "\n",
    "    # Global Average Pooling (GAP) - Exclude padded tokens\n",
    "    # Sum only over valid positions (padding_mask is False for valid positions)\n",
    "    sum_output = torch.sum(position_attn_output * (1 - padding_mask.unsqueeze(-1)), dim=1)  # (batch_size, feature_dim)\n",
    "    valid_count = torch.sum((1 - padding_mask).float(), dim=1)  # (batch_size,)\n",
    "    gap = sum_output / valid_count.unsqueeze(-1)  # Divide by number of valid positions\n",
    "\n",
    "    # Global Max Pooling (GMP) - Exclude padded tokens\n",
    "    # Set padded positions to -inf so they don't affect the max computation\n",
    "    position_attn_output_masked = position_attn_output * (1 - padding_mask.unsqueeze(-1)) + (padding_mask.unsqueeze(-1) * (- 1e10))\n",
    "    gmp, _ = torch.max(position_attn_output_masked, dim=1)  # (batch_size, feature_dim)\n",
    "\n",
    "    return gap, gmp\n",
    "\n",
    "\n",
    "class SinusoidalPositionalEncoding(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_len=3700):    \n",
    "\n",
    "        super(SinusoidalPositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, embedding_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embedding_dim, 2).float() * (-torch.log(torch.tensor(10000.0)) / embedding_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # Shape (1, max_len, embedding_dim)\n",
    "        self.register_buffer('pe', pe)  # Salvato come tensore fisso (non parametro)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "\n",
    "class TransformerRegression(nn.Module):\n",
    "    def __init__(self, input_dim=1280, num_heads=8, dropout_rate=0., num_experts=1, f_activation = nn.ReLU(), kernel_size=20, cross_att = True,\n",
    "                dual_cross_att=True):\n",
    "        \n",
    "        super(TransformerRegression, self).__init__()\n",
    "        self.cross_att = cross_att\n",
    "        self.dual_cross_att = dual_cross_att\n",
    "        \n",
    "        print(f'Cross Attention: {cross_att}')\n",
    "        print(f'Dual Cross Attention: {dual_cross_att}')\n",
    "\n",
    "        self.embedding_dim = input_dim\n",
    "        self.act = f_activation                                       \n",
    "        self.max_len = 3700\n",
    "        out_channels = 128  #num filtri conv 1D                  \n",
    "        kernel_size = 20\n",
    "        padding = 0\n",
    "        \n",
    "        self.conv1d = nn.Conv1d(in_channels=self.embedding_dim, \n",
    "                                             out_channels=out_channels, \n",
    "                                             kernel_size=kernel_size, \n",
    "                                             padding=padding) \n",
    "        \n",
    "        self.conv1d_wild = nn.Conv1d(in_channels=self.embedding_dim, \n",
    "                                             out_channels=out_channels, \n",
    "                                             kernel_size=kernel_size, \n",
    "                                             padding=padding)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(out_channels)\n",
    "        self.norm2 = nn.LayerNorm(out_channels)\n",
    "        \n",
    "        # Cross-attention layers\n",
    "        self.positional_encoding = SinusoidalPositionalEncoding(out_channels, 3700) \n",
    "        self.speach_att_type = True\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=out_channels, num_heads=num_heads, dropout=dropout_rate, batch_first=True )\n",
    "        self.inverse_attention = nn.MultiheadAttention(embed_dim=out_channels, num_heads=num_heads, dropout=dropout_rate, batch_first =True)\n",
    "        \n",
    "        if cross_att:\n",
    "            # Router (learns which expert to choose per token)\n",
    "            if dual_cross_att:\n",
    "                dim_position_wise_FFN = out_channels*2\n",
    "            else:\n",
    "                dim_position_wise_FFN = out_channels\n",
    "\n",
    "\n",
    "        else:\n",
    "            dim_position_wise_FFN = out_channels\n",
    "        \n",
    "        self.norm3 = nn.LayerNorm(dim_position_wise_FFN)\n",
    "        self.norm4 = nn.LayerNorm(dim_position_wise_FFN)        \n",
    "        self.router = nn.Linear(dim_position_wise_FFN, num_experts) #dim_position_wise_FFN*2\n",
    "        # Mixture of Experts (Switch FFN)\n",
    "        self.num_experts = num_experts\n",
    "        self.experts = nn.ModuleList([nn.Sequential(\n",
    "            nn.Linear(dim_position_wise_FFN, 512),\n",
    "            self.act,\n",
    "            nn.Linear(512, dim_position_wise_FFN)\n",
    "        ) for _ in range(num_experts)])\n",
    "        # self.experts = nn.Sequential(\n",
    "        #     nn.Linear(dim_position_wise_FFN, 512),\n",
    "        #     self.act,\n",
    "        #     nn.Linear(512, dim_position_wise_FFN)\n",
    "        #     )\n",
    "        \n",
    "\n",
    "        self.Linear_ddg = nn.Linear(dim_position_wise_FFN*2, 1)\n",
    "\n",
    "    def create_padding_mask(self, length, seq_len, batch_size):\n",
    "        \"\"\"\n",
    "        Create a padding mask for multihead attention.\n",
    "        length: Tensor of shape (batch_size,) containing the actual lengths of the sequences.\n",
    "        seq_len: The maximum sequence length.\n",
    "        batch_size: The number of sequences in the batch.\n",
    "        \n",
    "        Returns a padding mask of shape (batch_size, seq_len).\n",
    "        \"\"\"\n",
    "        mask = torch.arange(seq_len, device=length.device).unsqueeze(0) >= length.unsqueeze(1)\n",
    "        return mask\n",
    "\n",
    "    def forward(self, delta_w_m, x_wild, length):\n",
    "            # Add positional encoding\n",
    "            \n",
    "            delta_w_m = delta_w_m.transpose(1, 2)  # (batch_size, feature_dim, seq_len) -> (seq_len, batch_size, feature_dim)\n",
    "            C_delta_w_m = self.conv1d(delta_w_m)\n",
    "            # C_delta_w_m = self.act(C_delta_w_m)  #CASTRENSE USA RELU IO NON AVEVO MESSO NULLA \n",
    "            C_delta_w_m = C_delta_w_m.transpose(1, 2)  # (seq_len, batch_size, feature_dim) -> (batch_size, seq_len, feature_dim)\n",
    "            C_delta_w_m = self.positional_encoding(C_delta_w_m)\n",
    "            \n",
    "            x_wild = x_wild.transpose(1, 2)  # (batch_size, feature_dim, seq_len) -> (seq_len, batch_size, feature_dim)\n",
    "            C_x_wild = self.conv1d_wild(x_wild)\n",
    "            # C_x_wild = self.act(C_x_wild)  #CASTRENSE USA RELU IO NON AVEVO MESSO NULLA \n",
    "            C_x_wild = C_x_wild.transpose(1, 2)  # (seq_len, batch_size, feature_dim) -> (batch_size, seq_len, feature_dim)\n",
    "            C_x_wild = self.positional_encoding(C_x_wild)            \n",
    "            \n",
    "            batch_size, seq_len, feature_dim = C_x_wild.size()\n",
    "\n",
    "            padding_mask = self.create_padding_mask(length, seq_len, batch_size)        \n",
    "\n",
    "            if self.cross_att :\n",
    "                if self.dual_cross_att:\n",
    "                    \n",
    "                    if self.speach_att_type:\n",
    "                        print('ATTENTION TYPE: Dual cross Attention\\n q = wild , k = delta, v = delta and q = delta , k = wild, v = wild \\n ----------------------------------')\n",
    "                        self.speach_att_type = False\n",
    "                        \n",
    "                    direct_attn_output, _ = self.multihead_attention(C_x_wild, C_delta_w_m, C_delta_w_m, key_padding_mask=padding_mask)\n",
    "                    direct_attn_output += C_delta_w_m \n",
    "                    direct_attn_output = self.norm1(direct_attn_output)                        \n",
    "                    \n",
    "                    inverse_attn_output, _ = self.inverse_attention(C_delta_w_m, C_x_wild, C_x_wild, key_padding_mask=padding_mask)                   \n",
    "                    inverse_attn_output += C_x_wild  \n",
    "                    inverse_attn_output = self.norm2(inverse_attn_output)\n",
    "                    \n",
    "                    attn_output = torch.cat([direct_attn_output, inverse_attn_output], dim=-1)\n",
    "                    #combined_output = self.norm3(combined_output)\n",
    "\n",
    "                else:\n",
    "                    if self.speach_att_type:\n",
    "                        print('ATTENTION TYPE: Cross Attention \\n q = wild , k = delta, v = delta  \\n ----------------------------------')\n",
    "                        self.speach_att_type = False\n",
    "\n",
    "                    attn_output, _ = self.multihead_attention(C_x_wild, C_delta_w_m, C_delta_w_m, key_padding_mask=padding_mask)\n",
    "                    attn_output += C_delta_w_m \n",
    "                    attn_output = self.norm1(attn_output) \n",
    "            \n",
    "            else:\n",
    "                if self.speach_att_type:\n",
    "                    print('ATTENTION TYPE: Self Attention \\n q = delta , k = delta, v = delta  \\n ----------------------------------')\n",
    "                    self.speach_att_type = False\n",
    "                \n",
    "                attn_output, _ = self.multihead_attention(C_delta_w_m, C_delta_w_m, C_delta_w_m, key_padding_mask=padding_mask)\n",
    "                attn_output += C_delta_w_m\n",
    "                attn_output = self.norm1(attn_output)\n",
    "\n",
    "\n",
    "            ########\n",
    "            # Route tokens to experts\n",
    "            routing_logits = self.router(attn_output)  # Shape: [batch, seq_len, num_experts]\n",
    "            routing_weights = F.softmax(routing_logits, dim=-1)  # Probability distribution over experts\n",
    "            expert_indices = torch.argmax(routing_weights, dim=-1)  # Choose the most probable expert for each token\n",
    "            \n",
    "            # Apply selected expert\n",
    "            batch_size, seq_len, embed_dim = attn_output.shape\n",
    "            output = torch.zeros_like(attn_output)\n",
    "            for i in range(self.num_experts):\n",
    "                mask = (expert_indices == i).unsqueeze(-1).float()  # Mask for tokens assigned to expert i\n",
    "                expert_out = self.experts[i](attn_output) * mask  # Apply expert only to selected tokens\n",
    "                output += expert_out  # Aggregate expert outputs\n",
    "            ############√π\n",
    "\n",
    "            # output = self.experts(attn_output)\n",
    "\n",
    "            position_attn_output = attn_output + output\n",
    "\n",
    "            position_attn_output = self.norm3(position_attn_output)\n",
    "    \n",
    "            gap, gmp = apply_masked_pooling(position_attn_output, padding_mask)\n",
    "    \n",
    "            # Concatenate GAP and GMP\n",
    "            pooled_output = torch.cat([gap, gmp], dim=-1)  # (batch_size, 2 * feature_dim)\n",
    "    \n",
    "            # Pass through FFNN to predict DDG\n",
    "            x = self.Linear_ddg(pooled_output)        \n",
    "            \n",
    "            return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4cb6056-ecb1-4295-a449-4be5219c5bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_generation_pred(dataset_test, batch_size = 128, dataloader_shuffle = True, inv= False):\n",
    "    \n",
    "    dim_embedding = 1280\n",
    "    dataset_test = DeltaDataset(dataset_test, dim_embedding, inv = inv)\n",
    "    # Creazione DataLoader\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=dataloader_shuffle, collate_fn=collate_fn)\n",
    "\n",
    "    return dataloader_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dfd61ef-621d-4812-b09a-5437aedbb1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance_test(model, dataloader_test):\n",
    "\n",
    "    model.eval()\n",
    "    all_predictions_test = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "       \n",
    "        for i, batch in enumerate(dataloader_test):\n",
    "\n",
    "            predictions_test=output_model_from_batch(batch, model, device, train=False)\n",
    "            all_predictions_test.append(predictions_test)\n",
    "    \n",
    "    return all_predictions_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c1677da-b1ba-41cc-968e-557714b358f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3199214/710224360.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model = torch.load('../DeltaDelta_BELLO/JanusDDG_300epochs_plus25_hydra_slim.pth')#('JanusDDG_300epochs_plus25_hydra_slim.pth')#('JanusDDG_300epochs.pth')#('JanusDDG_300epochs_plus25_hydra_slim.pth')#('JanusDDG_300epochs_plus15_hydra_slim.pth')#('JanusDDG_300epochs.pth')#('JanusDDG_300_all_train.pth')#('JanusDDG_300epochs.pth')#(f'JanusDDG_300epochs.pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Cross_Attention_DDG(\n",
       "  (base_ddg): TransformerRegression(\n",
       "    (act): ReLU()\n",
       "    (conv1d): Conv1d(1280, 128, kernel_size=(20,), stride=(1,))\n",
       "    (conv1d_wild): Conv1d(1280, 128, kernel_size=(20,), stride=(1,))\n",
       "    (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (positional_encoding): SinusoidalPositionalEncoding()\n",
       "    (multihead_attention): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (inverse_attention): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (router): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (experts): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (Linear_ddg): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "input_dim = 1280\n",
    "\n",
    "transf_parameters={'input_dim':1280, 'num_heads':8,\n",
    "                    'dropout_rate':0.,}\n",
    "\n",
    "i=4\n",
    "best_model = torch.load('../DeltaDelta_BELLO/JanusDDG_300epochs_plus25_hydra_slim.pth')#('JanusDDG_300epochs_plus25_hydra_slim.pth')#('JanusDDG_300epochs.pth')#('JanusDDG_300epochs_plus25_hydra_slim.pth')#('JanusDDG_300epochs_plus15_hydra_slim.pth')#('JanusDDG_300epochs.pth')#('JanusDDG_300_all_train.pth')#('JanusDDG_300epochs.pth')#(f'JanusDDG_300epochs.pth')\n",
    "best_model.eval()\n",
    "#torch.load(f'DDGemb_Cross_4.pth')\n",
    "\n",
    "\n",
    "#IL MODELLO FINE TUNED PER SINGOLE √® JanusDDG_300epochs_plus25_hydra_slim   TRANSITIVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "433b4a4a-470e-4716-b1de-c2454134ebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_test = pd.read_pickle('Data/S669_GITHUB.pkl')#['../DeltaDelta_BELLO/ptmul_test.pkl']#['zeroshot_q3421.pkl']#['Ssym_correct_by_KORPM.pkl']#['test_TS16.pkl']#['ptmul_test.pkl']#['s669_hydra_Castrense.pkl']#['Ssym_correct_by_KORPM.pkl']#['s461_Castrense.pkl']#['s669_Castrense.pkl']#['../DeltaDelta_BELLO/cdna117k_fold_1.pkl'] + ['../DeltaDelta_BELLO/cdna117k_fold_2.pkl']#['s669_Castrense.pkl']\n",
    "#['dataset_doppie.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "531ba8fe-61f5-4e51-a443-777770c0bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_test_dir = dataloader_generation_pred(dataset_test=dataset_test,  batch_size = 1, dataloader_shuffle = False, inv= False)\n",
    "#for x in range(10):\n",
    "all_predictions_test_dir = model_performance_test(best_model,dataloader_test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6691fed-ea8f-4d8a-82d5-ef4006000053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11431189, -0.13115619,  0.1607447 , -0.13510053, -0.34920874,\n",
       "        0.13511008, -0.6159836 , -0.02062377,  0.11663852,  0.2492003 ,\n",
       "       -0.48888952,  0.5399512 , -0.07175331, -0.42336938, -0.76117593,\n",
       "       -0.39408144,  0.16212992,  0.35123318, -1.1982888 ,  0.14625174,\n",
       "        0.11561026,  0.08850323,  0.17889091, -0.26694697, -0.4221142 ,\n",
       "       -0.5527453 , -0.56517804, -1.6603603 , -0.58505076, -0.13119891,\n",
       "       -0.1985518 , -0.24318878, -1.6383183 , -1.266849  , -0.3179284 ,\n",
       "       -3.301221  , -3.0439787 , -1.7461777 , -0.60497785, -3.421257  ,\n",
       "       -3.1162083 , -2.320097  ,  0.33576518, -0.1985998 ,  0.02073852,\n",
       "        0.24327345,  0.3730581 , -0.2630698 , -2.8110585 , -2.17335   ,\n",
       "       -2.3282282 , -2.2220244 , -2.9223785 , -2.972989  , -2.3053417 ,\n",
       "       -1.7682157 , -1.3394463 , -0.33359408, -0.69262743, -2.3853426 ,\n",
       "        0.06818868, -0.16025242, -2.6745303 , -2.795452  , -2.0306082 ,\n",
       "       -2.8934853 , -2.1347373 , -1.8698704 , -0.27625477, -0.8312041 ,\n",
       "       -1.2187152 , -0.08860055, -0.40172583, -0.07845449, -1.1497738 ,\n",
       "       -0.1841819 , -0.79897344, -1.6044625 , -1.7127383 ,  1.2014024 ,\n",
       "       -0.42514545, -0.95349693, -0.825708  , -0.47931314,  0.11759321,\n",
       "        0.07177937, -1.4685508 , -0.39843366, -0.26592764, -0.2703436 ,\n",
       "       -0.5031594 ,  0.00550309,  0.21936363, -0.03916911, -0.21448499,\n",
       "        0.01440389, -0.08788092, -0.84062433,  0.33595848,  0.16799603,\n",
       "        0.09996298, -2.403981  , -1.4172634 , -0.02949748,  0.2837958 ,\n",
       "       -0.1440443 ,  1.120966  , -0.04374874,  0.5992343 ,  0.36872438,\n",
       "       -0.10299248,  0.05776098, -0.23478788,  0.29016164,  0.45256343,\n",
       "        0.5081431 ,  0.6825395 ,  0.01694881,  0.14940979,  0.02179073,\n",
       "       -0.05840952, -0.15389764,  0.4892586 ,  0.44892424, -0.6776259 ,\n",
       "        0.33094454,  0.29029387,  1.2221459 ,  0.03349963,  0.07308776,\n",
       "        0.08341774, -1.3845329 , -1.1819305 ,  0.6597189 , -1.6190523 ,\n",
       "       -0.62951297,  0.6017156 ,  0.17971657, -0.4359641 , -1.3766181 ,\n",
       "       -0.928728  , -0.48760095, -0.5803473 , -0.09295003, -0.39456952,\n",
       "       -0.37886816, -0.7338897 , -0.5708338 , -2.3632612 , -0.7189812 ,\n",
       "       -0.03991968, -0.39161965, -1.8359958 , -2.70246   , -2.9473524 ,\n",
       "       -1.684938  , -1.3332381 , -2.4176188 , -0.09447087, -0.38728955,\n",
       "       -2.2508261 , -2.2980204 , -0.3602878 ,  0.01438595, -1.2141576 ,\n",
       "       -1.1360066 , -1.0759912 , -0.5186325 , -0.34976882, -0.2588573 ,\n",
       "       -0.20587622, -0.35049987,  0.65890366, -0.76305383, -1.8374345 ,\n",
       "       -1.321142  , -1.4454832 , -2.02424   , -1.0411623 ,  0.01062026,\n",
       "       -1.1595082 , -0.41356045, -0.87727183, -1.0129056 , -1.7797142 ,\n",
       "       -2.058425  ,  1.2250245 , -0.1407359 , -2.4900532 , -2.4670897 ,\n",
       "       -0.2982387 , -0.77630705, -0.47571188, -0.6755613 , -0.76413924,\n",
       "       -0.0971839 , -0.301859  , -2.182638  , -0.3867896 , -0.16174632,\n",
       "        0.39341503, -2.0453622 , -2.9008265 , -2.6322331 ,  0.36459714,\n",
       "       -0.42556715,  0.36985356,  0.07956438, -0.15372173, -1.2674506 ,\n",
       "        0.11009002, -0.7390493 , -0.14590225, -0.3265063 , -2.7976627 ,\n",
       "       -2.9803138 , -2.5334048 , -0.80444133, -1.3154583 , -1.2456726 ,\n",
       "       -1.1853342 , -2.3422103 , -2.197181  , -2.489086  , -2.547206  ,\n",
       "       -2.583794  , -2.4742131 , -2.1694903 , -0.49994764, -1.7914298 ,\n",
       "        0.311964  , -0.11704788, -1.6733935 ,  0.02792141, -0.34775996,\n",
       "       -0.20169255, -1.1068062 , -0.25675875, -0.3760113 , -1.6656194 ,\n",
       "       -0.8377924 , -0.29968584, -1.3047001 , -1.416041  , -1.494965  ,\n",
       "       -0.9413502 , -0.6474244 , -0.12084848, -0.7066028 , -1.6678109 ,\n",
       "       -0.54111487, -1.6622143 ,  0.07480204, -0.1152363 , -2.349523  ,\n",
       "       -1.9528031 , -0.41151673, -2.2119565 , -0.2357817 ,  0.39640367,\n",
       "       -0.09417813,  0.18614356, -1.9201514 , -1.487386  , -1.1210926 ,\n",
       "        0.4604193 ,  0.44169044, -3.5234272 ,  0.23948193, -0.7397994 ,\n",
       "       -0.7005707 , -0.39074874, -0.3271079 , -0.03640346,  0.03659185,\n",
       "       -0.6993377 ,  0.1225192 ,  0.44585246,  0.315411  , -0.5213808 ,\n",
       "        1.0943716 , -0.1719139 , -0.5515545 , -0.1654872 , -0.45673722,\n",
       "       -1.4753094 , -0.9657592 , -1.324678  , -1.328675  , -0.36674553,\n",
       "       -0.446385  ,  0.17798507, -1.6293521 , -0.15054491,  0.10351066,\n",
       "        0.44396222,  0.03270827,  0.13236946, -0.68591154, -0.6846031 ,\n",
       "       -2.7011998 , -1.8317033 , -0.49967474, -2.8222692 , -2.912081  ,\n",
       "       -2.1111803 , -2.5142553 , -1.6267824 ,  0.49859136,  0.98361933,\n",
       "        0.32474807, -3.1431973 , -0.48722777, -0.15716743,  0.22066428,\n",
       "       -0.67564744, -1.3606853 , -1.3503124 , -1.4285967 , -0.07855071,\n",
       "       -0.80775887, -0.7068684 , -0.26694697, -0.4221142 , -0.9422015 ,\n",
       "       -0.5527453 , -0.5878256 , -0.58505076, -0.01561657, -0.13119891,\n",
       "       -0.1985518 , -1.9048979 , -0.87149626, -0.6778502 , -1.0448316 ,\n",
       "       -1.7669125 , -0.21740144, -0.8241879 , -0.1534588 , -0.60497785,\n",
       "        0.3531484 ,  0.33576518,  0.18567982,  0.47219127,  1.1532991 ,\n",
       "       -0.2281903 , -0.3695445 , -0.1985998 , -0.63998795,  0.02073852,\n",
       "        0.24327345, -2.3053417 , -1.8893659 , -2.0507379 , -1.6335361 ,\n",
       "       -1.3394463 ,  0.06818868, -0.603188  , -1.8698704 , -1.2187152 ,\n",
       "       -1.189868  , -0.01152662, -0.11084108,  0.06722187, -0.4032606 ,\n",
       "       -0.11298704, -0.25249434, -0.4869876 , -0.47498003, -0.33569002,\n",
       "       -0.9812807 ,  0.5462626 , -0.52104044, -0.5514439 , -0.45704043,\n",
       "       -0.09588193, -0.8949571 , -0.8155787 , -0.46636394, -0.3254664 ,\n",
       "       -0.62819093, -1.1709822 , -0.24909577, -0.4432914 , -0.29981568,\n",
       "       -0.29214507, -0.08252262, -0.44137686, -0.45452404, -0.2588933 ,\n",
       "        0.03387836, -0.5749935 , -0.26045674,  0.26683515,  0.26572412,\n",
       "        0.11513461, -0.43702614, -0.59938776, -0.6624236 , -0.6798378 ,\n",
       "        0.04982129, -0.36291486, -1.0674785 , -0.47597742, -0.68674946,\n",
       "       -0.54291975, -0.04045731, -0.40080094, -0.0089226 , -0.8542844 ,\n",
       "       -1.3043988 , -0.5261733 , -1.5530598 , -1.4335403 , -1.2739854 ,\n",
       "       -0.3281985 , -0.36843938, -0.87563217, -0.5047518 , -1.3481109 ,\n",
       "        0.00481704, -1.1859138 , -1.1152649 , -1.3607671 ,  0.59972715,\n",
       "       -0.14379656, -0.23724002, -2.1858187 , -1.1188114 , -0.2688677 ,\n",
       "       -0.06504972,  0.45058495, -2.9294019 , -2.062368  , -0.32553372,\n",
       "       -0.16751212,  0.77040184,  0.30444813, -0.33660895, -0.08733659,\n",
       "       -0.38772926, -0.10736034, -1.1243734 ,  0.65522975, -0.18848705,\n",
       "       -0.20999855,  0.18576416,  0.17640711,  0.48580557,  0.04877716,\n",
       "        0.38863856,  0.22008874, -0.46283808,  0.11899643,  0.10880361,\n",
       "        0.04508217, -0.57332397, -0.07530718, -1.3986895 , -0.15457577,\n",
       "       -0.9879149 , -1.4823773 ,  0.92701006, -2.2807174 , -2.481443  ,\n",
       "       -0.5252802 , -2.1969762 , -1.27522   ,  0.2753728 , -0.3858344 ,\n",
       "        0.17131415, -1.1933753 , -1.5795817 ,  0.16899745, -0.52628183,\n",
       "       -1.8780503 , -0.7435191 , -2.8619642 , -1.7985704 , -2.6235173 ,\n",
       "       -0.49368665, -0.6770193 , -1.306645  , -1.9173172 , -1.4724194 ,\n",
       "       -1.9362332 , -0.3512274 , -0.9741262 , -2.8845506 , -0.9969584 ,\n",
       "       -1.7020048 , -0.4804886 , -1.4768878 , -0.86888576, -0.9836521 ,\n",
       "       -1.031323  , -0.7086402 , -0.22892633, -0.7203277 , -0.92957425,\n",
       "       -0.8766732 , -2.1739435 , -2.280936  , -2.8188756 , -0.43522462,\n",
       "       -1.8881338 , -0.91507185, -1.0549278 , -0.65099597,  0.11274412,\n",
       "       -1.2600746 , -1.0644424 , -1.174407  , -0.94191563, -1.5560288 ,\n",
       "       -0.74813986, -0.24918616, -0.6416372 , -0.72571546, -1.7707299 ,\n",
       "       -1.7899756 , -2.0435712 , -1.6422741 , -2.5943995 , -1.5205822 ,\n",
       "       -0.894055  ,  0.77853125,  0.30989146, -0.31895763, -0.76761353,\n",
       "        0.23558736,  0.48421833, -1.8445929 , -1.0115784 , -0.265164  ,\n",
       "       -0.12941357, -1.1528349 , -0.4722212 , -0.78072286, -0.63205385,\n",
       "        0.06175515, -0.5316836 , -1.4497085 , -1.1372241 , -1.6171937 ,\n",
       "       -0.5251139 , -0.98140514, -0.10459122, -1.7866378 , -0.35437506,\n",
       "       -0.00816989, -0.37861216, -0.3889523 , -1.2336353 , -1.9974306 ,\n",
       "        0.20994346, -0.1839048 , -1.0808767 , -0.9290906 , -0.73011476,\n",
       "       -0.62187773, -1.3356458 , -0.78722686, -1.4220057 , -0.03189341,\n",
       "       -0.38646454, -1.2667937 , -0.05431281,  0.20690772, -1.0818301 ,\n",
       "       -0.5427231 , -1.4414412 , -1.2248874 , -1.7399354 , -1.1806879 ,\n",
       "       -0.54772574, -1.0809354 , -0.09681033, -0.01552777, -0.03938773,\n",
       "       -0.82445157, -0.491222  , -0.2342531 ,  0.48661235,  0.2928489 ,\n",
       "       -0.01231777, -0.16596249, -0.4132855 , -0.19427082,  0.01839599,\n",
       "       -1.9077239 , -2.1064224 , -0.68016326, -0.39833376, -1.1732973 ,\n",
       "       -0.58892846,  0.03611919, -1.5850734 , -2.1102207 , -0.57492286,\n",
       "       -0.29218876, -0.46618962, -0.7762041 , -1.4067132 , -0.29717833,\n",
       "       -3.0128102 , -0.88469934,  0.00397837, -0.34269077, -2.1725366 ,\n",
       "       -0.6407609 , -1.5933273 , -1.1403676 , -0.36521354, -0.8228091 ,\n",
       "       -1.5832095 , -2.427172  , -2.4985852 , -3.4463325 , -1.9977009 ,\n",
       "       -0.32245034, -0.7390493 ,  0.7439033 , -0.61816776, -0.2852942 ,\n",
       "       -0.15535164, -0.4391331 , -0.9382777 , -0.38421303, -0.34826362,\n",
       "       -0.5585198 , -1.0131826 , -2.0713897 , -2.6701102 , -2.0515351 ,\n",
       "        0.46166593, -2.243445  ,  1.0635512 ,  0.23966435, -0.5053233 ,\n",
       "       -1.69837   , -1.1154041 , -1.0418141 , -0.6351744 ,  0.05558868,\n",
       "       -0.35521966, -0.4725517 ,  0.2355053 , -1.5373642 , -0.14982069,\n",
       "       -0.23972273, -0.45353425, -1.9338713 , -0.7256658 ,  0.07951103,\n",
       "       -0.40152276, -0.40791002,  0.17596078, -0.3487329 , -0.20812109,\n",
       "       -0.7761422 ,  0.21676436, -0.2527071 , -0.26660997, -0.57479066,\n",
       "        1.5919418 , -1.2368073 , -1.2994831 ,  2.6938841 ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(torch.cat(all_predictions_test_dir, dim=0).cpu()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "058f6c44-d0d0-4a3d-8439-bc85bb4a6e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.5489732584234097, pvalue=6.379444575246027e-54)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(pd.Series(torch.cat(all_predictions_test_dir, dim=0).cpu()).values,[i['ddg'] for i in pd.read_pickle('../DeltaDelta_BELLO/s669_Castrense.pkl')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d3a423-a335-4e0c-a554-228a0a377a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddg = pd.DataFrame(pd.Series(torch.cat(all_predictions_test_dir, dim=0).cpu()).values)\n",
    "ddg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2200dd7-2bcf-41c0-8f2f-a256fcf22aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.read_csv('Results/Result_Tsuboyama_doppie_first50k.csv')\n",
    "preds = preds[preds['DDG'] != '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17152d8f-3f7d-4004-8549-667b657427d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.01366685967324699', '-0.25930853889603966',\n",
       "       '0.14123238152892093', ..., '-2.733004344088733',\n",
       "       '-1.9413717963098467', '-2.6021286581702276'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds['DDG'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a2bedfe-a1f6-47f1-91d9-53b44e3eae90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.1968380761732687, pvalue=0.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(preds['DDG_JanusDDG'],[float(i) for i in preds['DDG']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d70124-c184-4d50-aa25-1beff2e2e059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
